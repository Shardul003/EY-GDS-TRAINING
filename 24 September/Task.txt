Task:   “Build & Judge a Mini AI”


Part 1 — Chronology of AI

Write one real-world example for each stage:
Machine Learning → Alexa
Deep Learning → Social Media use deep learning to automatically filter inappropiate content
Computer Vision → Tesla Cars
NLP → E-mail Spam Detection
LLMs → Gemini, Microsoft Copilot

Part 2 — Deep Learning Architectures  
Match the model to the use case:              Use cases:
1. RNN                                        a) Image recognition
2. LSTM                                       b) Text translation (old Google Translate)
3. CNN                                        c) Predicting the next word in ChatGPT
4. Transformer                                d) Early speech-to-text systems

ANSWER- 1.d , 2.b , 3.a , 4.c

Part 3 — Frameworks

Choose one framework (PyTorch / TensorFlow / Keras).
In one sentence, explain why you would use it if you were a student making a cat-vs-dog classifier.

Answer- I would use Keras because it is Beginner Friendly API, this makes it easy for a student to quicky adapt to it and build a Deep Learning model without getting into too much complex details. 

Part 4 — Evaluation Metrics

Imagine you built a spam filter. 
Precision: If it marks 10 emails as spam and 7 are truly spam → what’s Precision?
Recall: If there were 12 spam emails in total, how many did it catch? (use same example)
F1 Score: Use the formula and calculate (round to 2 decimals).
MSE/MAE: Predict your friend’s age (actual = 15, prediction = 18). Which metric punishes the error more?
BLEU/ROUGE: AI translated “The cat sat on the mat” as “Cat is on the mat.” Which metric (BLEU/ROUGE) do you think would give a high score?

Answer:
Precision = True Positive / True Positive + False Positive
          TP=7
          FP=3
          Precision=7/7+3=0.7 
              =70%
Recall = True Positive / True Positive + False Negative
          TP=7
          FN=5 (12(Total spam)-7(Caught)=5(missed))
          Recall = 7/7+5 = 7/12 = 0.58 or 58%

F1 Score = 2 x ((Precision x Recall)/ (Precision + Recall))
          Precision = 0.70
          Recall = 0.58
          F1 = 2 x ((0.70 x 0.58)/(0.70 + 0.58))
          F1 Score= 0.63 or 63%
MSE vs MAE 
MSE(MEAN SQUARED ERROR):
          Actual = 15
          Prediction=18
          Error = 18-15 = 3
          MSE= error**2 = 3**2= 9
MAE(MEAN ABSOLUTE ERROR)
          MAE= |error|= 3
MSE Punishes the error more because it squares the difference.

BLEU/ROUGE:
BLEU
          Original - The cat sat on the mat
          Ai Based - Cat is on the mat.
          Prediction has overlap. But missed word "sat". Since one word is missing, BLEU score will drop but not too less
ROUGE
          Rough checks how much of the reference is covered. Prediction almost covers whole reference except "sat". So                ROUGE will give a higher score since most keys are included.

Part 5 — Responsible AI & Explainability
You built an AI that predicts loan approvals.
A customer asks, “Why was my loan rejected?”
Write one simple way to explain the decision fairly (e.g., “Your income was too low compared to the loan size”).

Answer - 
Clear - No technical
Fair - Based on data the customer can understand.
Actionable - Customers knows what factors influenced the outcome.
